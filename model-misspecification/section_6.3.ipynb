{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c114b7-6751-4192-9939-86d40967caba",
   "metadata": {},
   "source": [
    "# Section 6.3: Simulation Study: Effect of Model Mis-Specification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0b89de-40f4-4225-ba6f-f35428d8f648",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bec4524b-d6bd-4d3c-ac59-2d6b77ac8a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from ppi_py import logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "from aae import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde51688",
   "metadata": {},
   "source": [
    "### Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "440c2642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bias_reduction(df, true_theta):\n",
    "    # Group by method and m, compute MAPE for each group\n",
    "    df_grouped = df.groupby(['method', 'm']).agg({\n",
    "        'point_estimate': lambda x: np.mean(np.mean([\n",
    "            np.abs((est - true_theta)/(true_theta)) * 100\n",
    "            for est in x.values\n",
    "        ], axis=0))\n",
    "    }).reset_index()\n",
    "    # Group by method and m, compute mean squared error for each group\n",
    "    df_grouped_mse = df.groupby(['method', 'm']).agg({\n",
    "        'point_estimate': lambda x: np.mean(np.mean([\n",
    "            (est - true_theta)**2\n",
    "            for est in x.values\n",
    "        ], axis=0))\n",
    "    }).reset_index()\n",
    "\n",
    "    # Merge MAPE and MSE results\n",
    "    df_grouped = pd.merge(\n",
    "        df_grouped, \n",
    "        df_grouped_mse.rename(columns={'point_estimate': 'mse'}),\n",
    "        on=['method', 'm']\n",
    "    )\n",
    "\n",
    "    # Rename column for clarity\n",
    "    df_grouped = df_grouped.rename(columns={'point_estimate': 'mape'})\n",
    "    \n",
    "    diff_data = []\n",
    "    for m in ms:\n",
    "        mape_human = df_grouped[(df_grouped['method'] == 'Human-data-only') & (df_grouped['m'] == m)]['mape'].values[0]\n",
    "        for method in ['logistic', 'nn-1', 'nn-2']:\n",
    "            mape_method = df_grouped[(df_grouped['method'] == method) & (df_grouped['m'] == m)]['mape'].values[0]\n",
    "            diff = mape_method - mape_human\n",
    "            diff_data.append({'method': method, 'm': m, 'mape_diff': diff})\n",
    "            \n",
    "    df_diff = pd.DataFrame(diff_data)\n",
    "    # Pivot to get the desired table: rows are methods, columns are m\n",
    "    df_diff_table = df_diff.pivot(index='m', columns='method', values='mape_diff')\n",
    "    \n",
    "    # Display table with 2 decimal places\n",
    "    pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "    display(df_diff_table)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6536d0ff",
   "metadata": {},
   "source": [
    "### Import the simulated data set\n",
    "\n",
    "Load the data. The data set contains true choice label (```y```), augmented choice label (```y_aug```), and feature vectors (```X```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae4adf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 10\n",
    "n_samples = 1200\n",
    "with open(f'./data/sim/train_simcluster_{dx}_{n_samples}.pkl', 'rb') as f:\n",
    "    data = pkl.load(f)[0]\n",
    "Y_total = data[\"y\"]\n",
    "Yhat_total = data[\"y_aug\"]\n",
    "X_total1 = data[\"X\"]\n",
    "X_total = [X_total1[i][1, 1:] - X_total1[i][0, 1:] for i in range(len(X_total1))]\n",
    "X_total = np.array(X_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a5d540",
   "metadata": {},
   "source": [
    "### Problem setup\n",
    "\n",
    "Specify the range of values for the primary set size (```ms```), and number of trials (```num_trials```).\n",
    "\n",
    "Compute the ground-truth value of the estimand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34cc047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = Y_total.shape[0]  # Total number of labeled examples\n",
    "ms = np.array([50, 100, 150, 200]).astype(int)  # Test for different sizes of primary set\n",
    "n = 1000    # Size of the auxiliary set\n",
    "num_trials = 50\n",
    "optimizer_options = {\n",
    "    \"ftol\": 1e-5,\n",
    "    \"gtol\": 1e-5,\n",
    "    \"maxls\": 10000,\n",
    "    \"maxiter\": 10000,\n",
    "}\n",
    "\n",
    "# Saving results settings\n",
    "# WARNING::: If setting save_results to TRUE, the previous results will be OVERWRITTEN.\n",
    "save_results = False # TRUE to save results to pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b891ca9",
   "metadata": {},
   "source": [
    "### Running Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c8d635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:02<00:00,  1.25s/it]\n",
      "100%|██████████| 50/50 [01:50<00:00,  2.21s/it]\n",
      "100%|██████████| 50/50 [01:46<00:00,  2.13s/it]\n",
      "100%|██████████| 50/50 [02:06<00:00,  2.53s/it]\n"
     ]
    }
   ],
   "source": [
    "# Run AAE with various first-stage models\n",
    "X_total1_flat = flatten_full(X_total1)\n",
    "Yhat_total1 = (Yhat_total > 0.5).astype(int)\n",
    "methods = ['logistic', 'nn-1', 'nn-2']\n",
    "results = []\n",
    "for i in range(ms.shape[0]):\n",
    "    for j in tqdm(range(num_trials)):\n",
    "        m = ms[i]\n",
    "        rng = np.random.RandomState(j)\n",
    "        rand_idx = rng.permutation(n_total)\n",
    "        _X1, _X_unlabeled1 = np.array(X_total1)[rand_idx[:m]], np.array(X_total1)[rand_idx[m:m+n]]\n",
    "        _X_unlabeled1_flat = np.array(X_total1_flat)[rand_idx[m:m+n]]\n",
    "        _Y = Y_total[rand_idx[:m]]\n",
    "        _Yhat1, _Yhat_unlabeled1 = Yhat_total1[rand_idx[:m]], Yhat_total1[rand_idx[m:m+n]]\n",
    "\n",
    "        # AAE point estimates\n",
    "        g_models = {\n",
    "            'logistic': MLPClassifier(solver='adam', alpha=1e-4, activation='logistic', hidden_layer_sizes=(), random_state=1),\n",
    "            'nn-1': MLPClassifier(solver='adam', alpha=1e-4, activation='logistic', hidden_layer_sizes=(5,), random_state=1),\n",
    "            'nn-2': MLPClassifier(solver='adam', alpha=1e-4, activation='logistic', hidden_layer_sizes=(5,2), random_state=1)\n",
    "        }\n",
    "        for method in methods:\n",
    "            aae_pe = aae(_X1, _Y, _Yhat1, _X_unlabeled1, _Yhat_unlabeled1, _X_unlabeled1_flat, g_models[method], concat=1, n_epochs=1000, lr=1e-2)\n",
    "            \n",
    "            results += [\n",
    "                pd.DataFrame(\n",
    "                    [\n",
    "                        {\n",
    "                            \"method\": method,\n",
    "                            \"m\": m,\n",
    "                            \"trial\": j,\n",
    "                            \"point_estimate\": aae_pe,\n",
    "                        }\n",
    "                    ]\n",
    "                )\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dee02f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 326.30it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1129.82it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1143.35it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1150.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run human-data only estimation\n",
    "for i in range(ms.shape[0]):\n",
    "    for j in tqdm(range(num_trials)):\n",
    "        m = ms[i]\n",
    "        rng = np.random.RandomState(j)\n",
    "        rand_idx = rng.permutation(n_total)\n",
    "        _X, _X_unlabeled = X_total[rand_idx[:m]], X_total[rand_idx[m:m+n]]\n",
    "        _Y = Y_total[rand_idx[:m]]\n",
    "        _Yhat, _Yhat_unlabeled = Yhat_total[rand_idx[:m]],Yhat_total[rand_idx[m:m+n]]\n",
    "    \n",
    "        # Classical point estimate\n",
    "        human_data_only_pe = logistic(_X, _Y)\n",
    "\n",
    "        # Append results\n",
    "        results += [\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        \"method\": \"Human-data-only\",\n",
    "                        \"m\": m,\n",
    "                        \"trial\": j,\n",
    "                        \"point_estimate\": human_data_only_pe,\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84438f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to pickle file\n",
    "if save_results:        \n",
    "    with open(f'res/res_simcluster_{dx}_{n}_{num_trials}.pkl', 'wb') as f:\n",
    "        pkl.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c200bf3f",
   "metadata": {},
   "source": [
    "### Analyzing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11a914d",
   "metadata": {},
   "source": [
    "#### Loading results and ground truth parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb159df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 10\n",
    "n_samples = 1200\n",
    "n = 1000\n",
    "num_trials = 50\n",
    "with open(f'res/res_simcluster_{dx}_{n}_{num_trials}.pkl', 'rb') as f:\n",
    "    results =pkl.load(f)\n",
    "\n",
    "with open(f'./data/sim/train_simcluster_{dx}_{n_samples}.pkl', 'rb') as f:\n",
    "    data = pkl.load(f)[0]\n",
    "Y_total = data[\"y\"]\n",
    "Yhat_total = data[\"y_aug\"]\n",
    "X_total1 = data[\"X\"]\n",
    "X_total = [X_total1[i][1, 1:] - X_total1[i][0, 1:] for i in range(len(X_total1))]\n",
    "X_total = np.array(X_total)\n",
    "\n",
    "# Compute the best-in-class estimator\n",
    "true_theta = (\n",
    "    LogisticRegression(\n",
    "        penalty=None,\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=10000,\n",
    "        tol=1e-15,\n",
    "        fit_intercept=False,\n",
    "    )\n",
    "    .fit(X_total, Y_total)\n",
    "    .coef_.squeeze()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e2403",
   "metadata": {},
   "source": [
    "#### Compute the bias reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb973680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>method</th>\n",
       "      <th>logistic</th>\n",
       "      <th>nn-1</th>\n",
       "      <th>nn-2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-26612.90</td>\n",
       "      <td>-26792.41</td>\n",
       "      <td>-26825.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-386.35</td>\n",
       "      <td>-551.31</td>\n",
       "      <td>-574.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>-251.16</td>\n",
       "      <td>-389.32</td>\n",
       "      <td>-406.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-113.72</td>\n",
       "      <td>-236.97</td>\n",
       "      <td>-255.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "method  logistic      nn-1      nn-2\n",
       "m                                   \n",
       "50     -26612.90 -26792.41 -26825.15\n",
       "100      -386.35   -551.31   -574.82\n",
       "150      -251.16   -389.32   -406.86\n",
       "200      -113.72   -236.97   -255.02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.concat(results, axis=0, ignore_index=True)\n",
    "compute_bias_reduction(df, true_theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-r1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
